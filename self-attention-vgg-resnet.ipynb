{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\n# Define the input shape based on your dataset's image dimensions\ninput_shape = (48, 48, 1)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-28T14:00:28.187477Z","iopub.execute_input":"2023-12-28T14:00:28.187860Z","iopub.status.idle":"2023-12-28T14:00:40.548404Z","shell.execute_reply.started":"2023-12-28T14:00:28.187831Z","shell.execute_reply":"2023-12-28T14:00:40.547609Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport zipfile\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:01:18.455610Z","iopub.execute_input":"2023-12-28T14:01:18.456226Z","iopub.status.idle":"2023-12-28T14:01:18.817408Z","shell.execute_reply.started":"2023-12-28T14:01:18.456194Z","shell.execute_reply":"2023-12-28T14:01:18.816417Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/fer2013-cleaned-dataset/images1\"\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:01:20.177178Z","iopub.execute_input":"2023-12-28T14:01:20.177562Z","iopub.status.idle":"2023-12-28T14:01:20.181963Z","shell.execute_reply.started":"2023-12-28T14:01:20.177526Z","shell.execute_reply":"2023-12-28T14:01:20.180981Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nimport numpy as np\nimport tensorflow as tf\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:01:26.807393Z","iopub.execute_input":"2023-12-28T14:01:26.808297Z","iopub.status.idle":"2023-12-28T14:01:26.812986Z","shell.execute_reply.started":"2023-12-28T14:01:26.808259Z","shell.execute_reply":"2023-12-28T14:01:26.812014Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Layer, Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, Dense\nfrom keras.models import Model\n\nclass SelfAttention(Layer):\n    def __init__(self, channels):\n        super(SelfAttention, self).__init__()\n        self.channels = channels\n\n        # Query, Key, and Value transformations\n        self.W_q = Conv2D(channels // 8, (1, 1), padding='same')\n        self.W_k = Conv2D(channels // 8, (1, 1), padding='same')\n        self.W_v = Conv2D(channels, (1, 1), padding='same')\n\n    def call(self, x):\n        q = self.W_q(x)\n        k = self.W_k(x)\n        v = self.W_v(x)\n\n        # Reshape for compatibility with matrix multiplication\n        q = tf.reshape(q, [-1, tf.shape(q)[1] * tf.shape(q)[2], self.channels // 8])\n        k = tf.reshape(k, [-1, tf.shape(k)[1] * tf.shape(k)[2], self.channels // 8])\n        v = tf.reshape(v, [-1, tf.shape(v)[1] * tf.shape(v)[2], self.channels])\n\n        # Attention weights\n        attention_weights = tf.nn.softmax(tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(tf.shape(k)[-1], tf.float32)))\n\n        # Weighted sum\n        output = tf.matmul(attention_weights, v)\n\n        # Reshape back to the original spatial dimensions\n        output = tf.reshape(output, [-1, tf.shape(x)[1], tf.shape(x)[2], self.channels])\n\n        return output\n\ndef residual_block_with_attention(x, filters, kernel_size=(3, 3), stride=(1, 1), padding='same'):\n    shortcut = x\n\n    # First convolution layer\n    x = Conv2D(filters, kernel_size, strides=stride, padding=padding)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # Self-Attention layer\n    x_att = SelfAttention(filters)(x)\n\n    # Combine original features and attention features\n    x = Add()([x, x_att])\n\n    # Second convolution layer\n    x = Conv2D(filters, kernel_size, padding=padding)(x)\n    x = BatchNormalization()(x)\n\n    # Add the shortcut to the output\n    x = Add()([x, shortcut])\n    x = Activation('relu')(x)\n\n    return x\n\n# Build the model with self-attention\ndef build_vgg_with_resnet_and_attention(input_shape, num_classes):\n    input_layer = Input(shape=input_shape)\n\n    # VGG-like convolutional layers with residual blocks and self-attention\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n    x = residual_block_with_attention(x, 64)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    x = residual_block_with_attention(x, 128)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n    x = residual_block_with_attention(x, 256)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n    x = residual_block_with_attention(x, 512)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    # Flatten and add fully connected layers\n    x = Flatten()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dense(512, activation='relu')(x)\n\n    # Output layer\n    output_layer = Dense(num_classes, activation='softmax')(x)\n\n    # Create and compile the model\n    model = Model(inputs=input_layer, outputs=output_layer)\n\n    return model\n\n# Define the number of classes in your dataset\nnum_classes = 7  # Assuming FER 2013 has 7 emotion classes\n\n# Build the model with self-attention\nmodel = build_vgg_with_resnet_and_attention(input_shape, num_classes)\n\n# Compile the model with appropriate loss and optimizer\n\n# Print a summary of the model architecture\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:02:27.818238Z","iopub.execute_input":"2023-12-28T14:02:27.819007Z","iopub.status.idle":"2023-12-28T14:02:28.709982Z","shell.execute_reply.started":"2023-12-28T14:02:27.818975Z","shell.execute_reply":"2023-12-28T14:02:28.709027Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(None, 48, 48, 1)]          0         []                            \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 48, 48, 64)           640       ['input_2[0][0]']             \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 48, 48, 64)           36928     ['conv2d_12[0][0]']           \n                                                                                                  \n batch_normalization_8 (Bat  (None, 48, 48, 64)           256       ['conv2d_13[0][0]']           \n chNormalization)                                                                                 \n                                                                                                  \n activation_8 (Activation)   (None, 48, 48, 64)           0         ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n self_attention (SelfAttent  (None, 48, 48, 64)           5200      ['activation_8[0][0]']        \n ion)                                                                                             \n                                                                                                  \n add_4 (Add)                 (None, 48, 48, 64)           0         ['activation_8[0][0]',        \n                                                                     'self_attention[0][0]']      \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 48, 48, 64)           36928     ['add_4[0][0]']               \n                                                                                                  \n batch_normalization_9 (Bat  (None, 48, 48, 64)           256       ['conv2d_17[0][0]']           \n chNormalization)                                                                                 \n                                                                                                  \n add_5 (Add)                 (None, 48, 48, 64)           0         ['batch_normalization_9[0][0]'\n                                                                    , 'conv2d_12[0][0]']          \n                                                                                                  \n activation_9 (Activation)   (None, 48, 48, 64)           0         ['add_5[0][0]']               \n                                                                                                  \n max_pooling2d_4 (MaxPoolin  (None, 24, 24, 64)           0         ['activation_9[0][0]']        \n g2D)                                                                                             \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 24, 24, 128)          73856     ['max_pooling2d_4[0][0]']     \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 24, 24, 128)          147584    ['conv2d_18[0][0]']           \n                                                                                                  \n batch_normalization_10 (Ba  (None, 24, 24, 128)          512       ['conv2d_19[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_10 (Activation)  (None, 24, 24, 128)          0         ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n self_attention_1 (SelfAtte  (None, 24, 24, 128)          20640     ['activation_10[0][0]']       \n ntion)                                                                                           \n                                                                                                  \n add_6 (Add)                 (None, 24, 24, 128)          0         ['activation_10[0][0]',       \n                                                                     'self_attention_1[0][0]']    \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 24, 24, 128)          147584    ['add_6[0][0]']               \n                                                                                                  \n batch_normalization_11 (Ba  (None, 24, 24, 128)          512       ['conv2d_23[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_7 (Add)                 (None, 24, 24, 128)          0         ['batch_normalization_11[0][0]\n                                                                    ',                            \n                                                                     'conv2d_18[0][0]']           \n                                                                                                  \n activation_11 (Activation)  (None, 24, 24, 128)          0         ['add_7[0][0]']               \n                                                                                                  \n max_pooling2d_5 (MaxPoolin  (None, 12, 12, 128)          0         ['activation_11[0][0]']       \n g2D)                                                                                             \n                                                                                                  \n conv2d_24 (Conv2D)          (None, 12, 12, 256)          295168    ['max_pooling2d_5[0][0]']     \n                                                                                                  \n conv2d_25 (Conv2D)          (None, 12, 12, 256)          590080    ['conv2d_24[0][0]']           \n                                                                                                  \n batch_normalization_12 (Ba  (None, 12, 12, 256)          1024      ['conv2d_25[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_12 (Activation)  (None, 12, 12, 256)          0         ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n self_attention_2 (SelfAtte  (None, 12, 12, 256)          82240     ['activation_12[0][0]']       \n ntion)                                                                                           \n                                                                                                  \n add_8 (Add)                 (None, 12, 12, 256)          0         ['activation_12[0][0]',       \n                                                                     'self_attention_2[0][0]']    \n                                                                                                  \n conv2d_29 (Conv2D)          (None, 12, 12, 256)          590080    ['add_8[0][0]']               \n                                                                                                  \n batch_normalization_13 (Ba  (None, 12, 12, 256)          1024      ['conv2d_29[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_9 (Add)                 (None, 12, 12, 256)          0         ['batch_normalization_13[0][0]\n                                                                    ',                            \n                                                                     'conv2d_24[0][0]']           \n                                                                                                  \n activation_13 (Activation)  (None, 12, 12, 256)          0         ['add_9[0][0]']               \n                                                                                                  \n max_pooling2d_6 (MaxPoolin  (None, 6, 6, 256)            0         ['activation_13[0][0]']       \n g2D)                                                                                             \n                                                                                                  \n conv2d_30 (Conv2D)          (None, 6, 6, 512)            1180160   ['max_pooling2d_6[0][0]']     \n                                                                                                  \n conv2d_31 (Conv2D)          (None, 6, 6, 512)            2359808   ['conv2d_30[0][0]']           \n                                                                                                  \n batch_normalization_14 (Ba  (None, 6, 6, 512)            2048      ['conv2d_31[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_14 (Activation)  (None, 6, 6, 512)            0         ['batch_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n self_attention_3 (SelfAtte  (None, 6, 6, 512)            328320    ['activation_14[0][0]']       \n ntion)                                                                                           \n                                                                                                  \n add_10 (Add)                (None, 6, 6, 512)            0         ['activation_14[0][0]',       \n                                                                     'self_attention_3[0][0]']    \n                                                                                                  \n conv2d_35 (Conv2D)          (None, 6, 6, 512)            2359808   ['add_10[0][0]']              \n                                                                                                  \n batch_normalization_15 (Ba  (None, 6, 6, 512)            2048      ['conv2d_35[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n add_11 (Add)                (None, 6, 6, 512)            0         ['batch_normalization_15[0][0]\n                                                                    ',                            \n                                                                     'conv2d_30[0][0]']           \n                                                                                                  \n activation_15 (Activation)  (None, 6, 6, 512)            0         ['add_11[0][0]']              \n                                                                                                  \n max_pooling2d_7 (MaxPoolin  (None, 3, 3, 512)            0         ['activation_15[0][0]']       \n g2D)                                                                                             \n                                                                                                  \n flatten_1 (Flatten)         (None, 4608)                 0         ['max_pooling2d_7[0][0]']     \n                                                                                                  \n dense_3 (Dense)             (None, 512)                  2359808   ['flatten_1[0][0]']           \n                                                                                                  \n dense_4 (Dense)             (None, 512)                  262656    ['dense_3[0][0]']             \n                                                                                                  \n dense_5 (Dense)             (None, 7)                    3591      ['dense_4[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 10888759 (41.54 MB)\nTrainable params: 10884919 (41.52 MB)\nNon-trainable params: 3840 (15.00 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_generator = ImageDataGenerator(rescale=1./255)\ntest_data_generator = ImageDataGenerator(rescale=1./255)\n\ntrain_data = train_data_generator.flow_from_directory(\n    os.path.join(dataset_path, 'train'),\n    color_mode='grayscale',\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True\n)\n\ntest_data = test_data_generator.flow_from_directory(\n    os.path.join(dataset_path, 'test'),\n    color_mode='grayscale',\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:03:30.068995Z","iopub.execute_input":"2023-12-28T14:03:30.069384Z","iopub.status.idle":"2023-12-28T14:03:57.576530Z","shell.execute_reply.started":"2023-12-28T14:03:30.069352Z","shell.execute_reply":"2023-12-28T14:03:57.575756Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 28044 images belonging to 7 classes.\nFound 7177 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"num_train_samples = 28044\nnum_test_samples = 7177","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:04:04.449246Z","iopub.execute_input":"2023-12-28T14:04:04.450254Z","iopub.status.idle":"2023-12-28T14:04:04.454454Z","shell.execute_reply.started":"2023-12-28T14:04:04.450218Z","shell.execute_reply":"2023-12-28T14:04:04.453324Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:04:06.600696Z","iopub.execute_input":"2023-12-28T14:04:06.601366Z","iopub.status.idle":"2023-12-28T14:04:06.622578Z","shell.execute_reply.started":"2023-12-28T14:04:06.601331Z","shell.execute_reply":"2023-12-28T14:04:06.621771Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:04:10.211864Z","iopub.execute_input":"2023-12-28T14:04:10.212594Z","iopub.status.idle":"2023-12-28T14:04:10.216674Z","shell.execute_reply.started":"2023-12-28T14:04:10.212564Z","shell.execute_reply":"2023-12-28T14:04:10.215757Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    steps_per_epoch=num_train_samples // batch_size,\n    epochs=10,\n    callbacks=[early_stopping],\n    batch_size=batch_size,\n    validation_data=test_data\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:04:13.236803Z","iopub.execute_input":"2023-12-28T14:04:13.237663Z","iopub.status.idle":"2023-12-28T14:18:11.740480Z","shell.execute_reply.started":"2023-12-28T14:04:13.237630Z","shell.execute_reply":"2023-12-28T14:18:11.739500Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/10\n438/438 [==============================] - 176s 355ms/step - loss: 1.9703 - accuracy: 0.2367 - val_loss: 1.7966 - val_accuracy: 0.2480\nEpoch 2/10\n438/438 [==============================] - 74s 168ms/step - loss: 1.7028 - accuracy: 0.3152 - val_loss: 1.7498 - val_accuracy: 0.2530\nEpoch 3/10\n438/438 [==============================] - 73s 167ms/step - loss: 1.5762 - accuracy: 0.3783 - val_loss: 1.5463 - val_accuracy: 0.3784\nEpoch 4/10\n438/438 [==============================] - 73s 168ms/step - loss: 1.4598 - accuracy: 0.4272 - val_loss: 1.5619 - val_accuracy: 0.3680\nEpoch 5/10\n438/438 [==============================] - 74s 168ms/step - loss: 1.3622 - accuracy: 0.4659 - val_loss: 1.4907 - val_accuracy: 0.4038\nEpoch 6/10\n438/438 [==============================] - 73s 167ms/step - loss: 1.2835 - accuracy: 0.4992 - val_loss: 1.2892 - val_accuracy: 0.5008\nEpoch 7/10\n438/438 [==============================] - 74s 168ms/step - loss: 1.2528 - accuracy: 0.5152 - val_loss: 1.3616 - val_accuracy: 0.4651\nEpoch 8/10\n438/438 [==============================] - 73s 167ms/step - loss: 1.2147 - accuracy: 0.5315 - val_loss: 1.2289 - val_accuracy: 0.5299\nEpoch 9/10\n438/438 [==============================] - 74s 169ms/step - loss: 1.1525 - accuracy: 0.5601 - val_loss: 1.2545 - val_accuracy: 0.5136\nEpoch 10/10\n438/438 [==============================] - 74s 168ms/step - loss: 1.1059 - accuracy: 0.5762 - val_loss: 1.2780 - val_accuracy: 0.5054\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\ny_true = test_data.classes  # Assuming you're using flow_from_directory\npredictions = model.predict(test_data)\n\n# Convert predictions to class labels\ny_pred = np.argmax(predictions, axis=1)\n\n# Compute metrics\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, average='weighted')\nrecall = recall_score(y_true, y_pred, average='weighted')\nf1 = f1_score(y_true, y_pred, average='weighted')\n\n# If binary classification, compute AUC  # AUC is not applicable for multi-class\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:18:24.142605Z","iopub.execute_input":"2023-12-28T14:18:24.143355Z","iopub.status.idle":"2023-12-28T14:18:31.789009Z","shell.execute_reply.started":"2023-12-28T14:18:24.143322Z","shell.execute_reply":"2023-12-28T14:18:31.788064Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"113/113 [==============================] - 7s 60ms/step\nAccuracy: 0.5053643583670057\nPrecision: 0.5142106091318197\nRecall: 0.5053643583670057\nF1 Score: 0.4969658092571358\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}