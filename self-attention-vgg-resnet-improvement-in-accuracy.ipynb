{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\n# Define the input shape based on your dataset's image dimensions\ninput_shape = (48, 48, 1)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-28T14:59:41.748711Z","iopub.execute_input":"2023-12-28T14:59:41.749552Z","iopub.status.idle":"2023-12-28T14:59:53.565498Z","shell.execute_reply.started":"2023-12-28T14:59:41.749517Z","shell.execute_reply":"2023-12-28T14:59:53.564501Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport zipfile\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense","metadata":{"execution":{"iopub.status.busy":"2023-12-28T14:59:58.565400Z","iopub.execute_input":"2023-12-28T14:59:58.566410Z","iopub.status.idle":"2023-12-28T14:59:58.909618Z","shell.execute_reply.started":"2023-12-28T14:59:58.566372Z","shell.execute_reply":"2023-12-28T14:59:58.908856Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/fer2013-cleaned-dataset/images1\"\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:00:04.287203Z","iopub.execute_input":"2023-12-28T15:00:04.287570Z","iopub.status.idle":"2023-12-28T15:00:04.291762Z","shell.execute_reply.started":"2023-12-28T15:00:04.287544Z","shell.execute_reply":"2023-12-28T15:00:04.290750Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nimport numpy as np\nimport tensorflow as tf\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:00:06.610942Z","iopub.execute_input":"2023-12-28T15:00:06.611322Z","iopub.status.idle":"2023-12-28T15:00:06.616461Z","shell.execute_reply.started":"2023-12-28T15:00:06.611289Z","shell.execute_reply":"2023-12-28T15:00:06.615298Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Layer, Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, Dense\nfrom keras.models import Model\n\nclass SelfAttention(Layer):\n    def __init__(self, channels):\n        super(SelfAttention, self).__init__()\n        self.channels = channels\n\n        # Query, Key, and Value transformations\n        self.W_q = Conv2D(channels // 8, (1, 1), padding='same')\n        self.W_k = Conv2D(channels // 8, (1, 1), padding='same')\n        self.W_v = Conv2D(channels, (1, 1), padding='same')\n\n    def call(self, x):\n        q = self.W_q(x)\n        k = self.W_k(x)\n        v = self.W_v(x)\n\n        # Reshape for compatibility with matrix multiplication\n        q = tf.reshape(q, [-1, tf.shape(q)[1] * tf.shape(q)[2], self.channels // 8])\n        k = tf.reshape(k, [-1, tf.shape(k)[1] * tf.shape(k)[2], self.channels // 8])\n        v = tf.reshape(v, [-1, tf.shape(v)[1] * tf.shape(v)[2], self.channels])\n\n        # Attention weights\n        attention_weights = tf.nn.softmax(tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(tf.shape(k)[-1], tf.float32)))\n\n        # Weighted sum\n        output = tf.matmul(attention_weights, v)\n\n        # Reshape back to the original spatial dimensions\n        output = tf.reshape(output, [-1, tf.shape(x)[1], tf.shape(x)[2], self.channels])\n\n        return output\n\ndef residual_block_with_attention(x, filters, kernel_size=(3, 3), stride=(1, 1), padding='same'):\n    shortcut = x\n\n    # First convolution layer\n    x = Conv2D(filters, kernel_size, strides=stride, padding=padding)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # Self-Attention layer\n    x_att = SelfAttention(filters)(x)\n\n    # Combine original features and attention features\n    x = Add()([x, x_att])\n\n    # Second convolution layer\n    x = Conv2D(filters, kernel_size, padding=padding)(x)\n    x = BatchNormalization()(x)\n\n    # Add the shortcut to the output\n    x = Add()([x, shortcut])\n    x = Activation('relu')(x)\n\n    return x\n\n# Build the model with self-attention\ndef build_vgg_with_resnet_and_attention(input_shape, num_classes):\n    input_layer = Input(shape=input_shape)\n\n    # VGG-like convolutional layers with residual blocks and self-attention\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n    x = residual_block_with_attention(x, 64)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    x = residual_block_with_attention(x, 128)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n    x = residual_block_with_attention(x, 256)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n    x = residual_block_with_attention(x, 512)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n\n    # Flatten and add fully connected layers\n    x = Flatten()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dense(512, activation='relu')(x)\n\n    # Output layer\n    output_layer = Dense(num_classes, activation='softmax')(x)\n\n    # Create and compile the model\n    model = Model(inputs=input_layer, outputs=output_layer)\n\n    return model\n\n# Define the number of classes in your dataset\nnum_classes = 7  # Assuming FER 2013 has 7 emotion classes\n\n# Build the model with self-attention\nmodel = build_vgg_with_resnet_and_attention(input_shape, num_classes)\n\n# Compile the model with appropriate loss and optimizer\n\n# Print a summary of the model architecture\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:00:08.198596Z","iopub.execute_input":"2023-12-28T15:00:08.199326Z","iopub.status.idle":"2023-12-28T15:00:12.126996Z","shell.execute_reply.started":"2023-12-28T15:00:08.199296Z","shell.execute_reply":"2023-12-28T15:00:12.126073Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 48, 48, 1)]          0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 48, 48, 64)           640       ['input_1[0][0]']             \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 48, 48, 64)           36928     ['conv2d[0][0]']              \n                                                                                                  \n batch_normalization (Batch  (None, 48, 48, 64)           256       ['conv2d_1[0][0]']            \n Normalization)                                                                                   \n                                                                                                  \n activation (Activation)     (None, 48, 48, 64)           0         ['batch_normalization[0][0]'] \n                                                                                                  \n self_attention (SelfAttent  (None, 48, 48, 64)           5200      ['activation[0][0]']          \n ion)                                                                                             \n                                                                                                  \n add (Add)                   (None, 48, 48, 64)           0         ['activation[0][0]',          \n                                                                     'self_attention[0][0]']      \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 48, 48, 64)           36928     ['add[0][0]']                 \n                                                                                                  \n batch_normalization_1 (Bat  (None, 48, 48, 64)           256       ['conv2d_5[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n add_1 (Add)                 (None, 48, 48, 64)           0         ['batch_normalization_1[0][0]'\n                                                                    , 'conv2d[0][0]']             \n                                                                                                  \n activation_1 (Activation)   (None, 48, 48, 64)           0         ['add_1[0][0]']               \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 24, 24, 64)           0         ['activation_1[0][0]']        \n D)                                                                                               \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 24, 24, 128)          73856     ['max_pooling2d[0][0]']       \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 24, 24, 128)          147584    ['conv2d_6[0][0]']            \n                                                                                                  \n batch_normalization_2 (Bat  (None, 24, 24, 128)          512       ['conv2d_7[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_2 (Activation)   (None, 24, 24, 128)          0         ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n self_attention_1 (SelfAtte  (None, 24, 24, 128)          20640     ['activation_2[0][0]']        \n ntion)                                                                                           \n                                                                                                  \n add_2 (Add)                 (None, 24, 24, 128)          0         ['activation_2[0][0]',        \n                                                                     'self_attention_1[0][0]']    \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 24, 24, 128)          147584    ['add_2[0][0]']               \n                                                                                                  \n batch_normalization_3 (Bat  (None, 24, 24, 128)          512       ['conv2d_11[0][0]']           \n chNormalization)                                                                                 \n                                                                                                  \n add_3 (Add)                 (None, 24, 24, 128)          0         ['batch_normalization_3[0][0]'\n                                                                    , 'conv2d_6[0][0]']           \n                                                                                                  \n activation_3 (Activation)   (None, 24, 24, 128)          0         ['add_3[0][0]']               \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 12, 12, 128)          0         ['activation_3[0][0]']        \n g2D)                                                                                             \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 12, 12, 256)          295168    ['max_pooling2d_1[0][0]']     \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 12, 12, 256)          590080    ['conv2d_12[0][0]']           \n                                                                                                  \n batch_normalization_4 (Bat  (None, 12, 12, 256)          1024      ['conv2d_13[0][0]']           \n chNormalization)                                                                                 \n                                                                                                  \n activation_4 (Activation)   (None, 12, 12, 256)          0         ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n self_attention_2 (SelfAtte  (None, 12, 12, 256)          82240     ['activation_4[0][0]']        \n ntion)                                                                                           \n                                                                                                  \n add_4 (Add)                 (None, 12, 12, 256)          0         ['activation_4[0][0]',        \n                                                                     'self_attention_2[0][0]']    \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 12, 12, 256)          590080    ['add_4[0][0]']               \n                                                                                                  \n batch_normalization_5 (Bat  (None, 12, 12, 256)          1024      ['conv2d_17[0][0]']           \n chNormalization)                                                                                 \n                                                                                                  \n add_5 (Add)                 (None, 12, 12, 256)          0         ['batch_normalization_5[0][0]'\n                                                                    , 'conv2d_12[0][0]']          \n                                                                                                  \n activation_5 (Activation)   (None, 12, 12, 256)          0         ['add_5[0][0]']               \n                                                                                                  \n max_pooling2d_2 (MaxPoolin  (None, 6, 6, 256)            0         ['activation_5[0][0]']        \n g2D)                                                                                             \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 6, 6, 512)            1180160   ['max_pooling2d_2[0][0]']     \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 6, 6, 512)            2359808   ['conv2d_18[0][0]']           \n                                                                                                  \n batch_normalization_6 (Bat  (None, 6, 6, 512)            2048      ['conv2d_19[0][0]']           \n chNormalization)                                                                                 \n                                                                                                  \n activation_6 (Activation)   (None, 6, 6, 512)            0         ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n self_attention_3 (SelfAtte  (None, 6, 6, 512)            328320    ['activation_6[0][0]']        \n ntion)                                                                                           \n                                                                                                  \n add_6 (Add)                 (None, 6, 6, 512)            0         ['activation_6[0][0]',        \n                                                                     'self_attention_3[0][0]']    \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 6, 6, 512)            2359808   ['add_6[0][0]']               \n                                                                                                  \n batch_normalization_7 (Bat  (None, 6, 6, 512)            2048      ['conv2d_23[0][0]']           \n chNormalization)                                                                                 \n                                                                                                  \n add_7 (Add)                 (None, 6, 6, 512)            0         ['batch_normalization_7[0][0]'\n                                                                    , 'conv2d_18[0][0]']          \n                                                                                                  \n activation_7 (Activation)   (None, 6, 6, 512)            0         ['add_7[0][0]']               \n                                                                                                  \n max_pooling2d_3 (MaxPoolin  (None, 3, 3, 512)            0         ['activation_7[0][0]']        \n g2D)                                                                                             \n                                                                                                  \n flatten (Flatten)           (None, 4608)                 0         ['max_pooling2d_3[0][0]']     \n                                                                                                  \n dense (Dense)               (None, 512)                  2359808   ['flatten[0][0]']             \n                                                                                                  \n dense_1 (Dense)             (None, 512)                  262656    ['dense[0][0]']               \n                                                                                                  \n dense_2 (Dense)             (None, 7)                    3591      ['dense_1[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 10888759 (41.54 MB)\nTrainable params: 10884919 (41.52 MB)\nNon-trainable params: 3840 (15.00 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_generator = ImageDataGenerator(rescale=1./255)\ntest_data_generator = ImageDataGenerator(rescale=1./255)\n\ntrain_data = train_data_generator.flow_from_directory(\n    os.path.join(dataset_path, 'train'),\n    color_mode='grayscale',\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True\n)\n\ntest_data = test_data_generator.flow_from_directory(\n    os.path.join(dataset_path, 'test'),\n    color_mode='grayscale',\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:00:19.079491Z","iopub.execute_input":"2023-12-28T15:00:19.080253Z","iopub.status.idle":"2023-12-28T15:00:59.334045Z","shell.execute_reply.started":"2023-12-28T15:00:19.080220Z","shell.execute_reply":"2023-12-28T15:00:59.333031Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 28044 images belonging to 7 classes.\nFound 7177 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"num_train_samples = 28044\nnum_test_samples = 7177","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:01:05.871198Z","iopub.execute_input":"2023-12-28T15:01:05.871593Z","iopub.status.idle":"2023-12-28T15:01:05.876119Z","shell.execute_reply.started":"2023-12-28T15:01:05.871564Z","shell.execute_reply":"2023-12-28T15:01:05.875163Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:01:09.429133Z","iopub.execute_input":"2023-12-28T15:01:09.429790Z","iopub.status.idle":"2023-12-28T15:01:09.450451Z","shell.execute_reply.started":"2023-12-28T15:01:09.429759Z","shell.execute_reply":"2023-12-28T15:01:09.449667Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:28:00.565260Z","iopub.execute_input":"2023-12-28T15:28:00.565688Z","iopub.status.idle":"2023-12-28T15:28:00.570779Z","shell.execute_reply.started":"2023-12-28T15:28:00.565656Z","shell.execute_reply":"2023-12-28T15:28:00.569841Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    steps_per_epoch=num_train_samples // batch_size,\n    epochs=100,\n    callbacks=[early_stopping],\n    batch_size=batch_size,\n    validation_data=test_data\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:28:01.398538Z","iopub.execute_input":"2023-12-28T15:28:01.398933Z","iopub.status.idle":"2023-12-28T15:35:24.336847Z","shell.execute_reply.started":"2023-12-28T15:28:01.398901Z","shell.execute_reply":"2023-12-28T15:35:24.335803Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/100\n438/438 [==============================] - 73s 167ms/step - loss: 0.6969 - accuracy: 0.7390 - val_loss: 1.2763 - val_accuracy: 0.5548\nEpoch 2/100\n438/438 [==============================] - 74s 168ms/step - loss: 0.6676 - accuracy: 0.7504 - val_loss: 1.3279 - val_accuracy: 0.5734\nEpoch 3/100\n438/438 [==============================] - 74s 168ms/step - loss: 0.5977 - accuracy: 0.7778 - val_loss: 1.3539 - val_accuracy: 0.5682\nEpoch 4/100\n438/438 [==============================] - 74s 170ms/step - loss: 0.5798 - accuracy: 0.7835 - val_loss: 1.5085 - val_accuracy: 0.5526\nEpoch 5/100\n438/438 [==============================] - 74s 169ms/step - loss: 0.5216 - accuracy: 0.8040 - val_loss: 1.4284 - val_accuracy: 0.5763\nEpoch 6/100\n438/438 [==============================] - 74s 169ms/step - loss: 0.4507 - accuracy: 0.8352 - val_loss: 1.5143 - val_accuracy: 0.5754\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\ny_true = test_data.classes  # Assuming you're using flow_from_directory\npredictions = model.predict(test_data)\n\n\ny_pred = np.argmax(predictions, axis=1)\n\n\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, average='weighted')\nrecall = recall_score(y_true, y_pred, average='weighted')\nf1 = f1_score(y_true, y_pred, average='weighted')\n\n\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:35:33.779025Z","iopub.execute_input":"2023-12-28T15:35:33.779382Z","iopub.status.idle":"2023-12-28T15:35:40.772975Z","shell.execute_reply.started":"2023-12-28T15:35:33.779353Z","shell.execute_reply":"2023-12-28T15:35:40.772078Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"113/113 [==============================] - 7s 54ms/step\nAccuracy: 0.5754493520969765\nPrecision: 0.5747998300032895\nRecall: 0.5754493520969765\nF1 Score: 0.5744061574469045\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, roc_auc_score\n\n# Assuming you have trained your model and evaluated it\n# test_data, num_test_samples, batch_size, model\n\n# Make predictions on test data\npredictions = model.predict(test_data, steps=num_test_samples // batch_size)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = test_data.classes[:len(predicted_classes)]  # Extract true classes from the test_data\n\n# Calculate AUC score\nauc = roc_auc_score(test_data.labels[:len(predicted_classes)], predictions, multi_class='ovr') \n\n# Generate classification report\nreport = classification_report(true_classes, predicted_classes)\nprint(\"Classification Report:\\n\", report)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-28T15:37:52.543306Z","iopub.execute_input":"2023-12-28T15:37:52.544017Z","iopub.status.idle":"2023-12-28T15:37:59.279338Z","shell.execute_reply.started":"2023-12-28T15:37:52.543983Z","shell.execute_reply":"2023-12-28T15:37:59.278436Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"112/112 [==============================] - 7s 58ms/step\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.50      0.44      0.47       957\n           1       0.47      0.41      0.44       111\n           2       0.40      0.38      0.39      1024\n           3       0.78      0.81      0.80      1774\n           4       0.50      0.54      0.52      1233\n           5       0.45      0.48      0.46      1247\n           6       0.75      0.69      0.72       822\n\n    accuracy                           0.58      7168\n   macro avg       0.55      0.54      0.54      7168\nweighted avg       0.57      0.58      0.57      7168\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}