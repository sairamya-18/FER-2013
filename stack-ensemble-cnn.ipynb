{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport zipfile\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-10T04:13:02.160027Z","iopub.execute_input":"2024-01-10T04:13:02.160326Z","iopub.status.idle":"2024-01-10T04:13:15.652671Z","shell.execute_reply.started":"2024-01-10T04:13:02.160299Z","shell.execute_reply":"2024-01-10T04:13:15.651878Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndataset_path = \"/kaggle/input/fer2013-cleaned-dataset/images1\"\n\nnum_classes = 7\n\ninput_shape = (48, 48, 1)\n\nbatch_size = 64\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:13:20.127081Z","iopub.execute_input":"2024-01-10T04:13:20.127681Z","iopub.status.idle":"2024-01-10T04:13:20.132577Z","shell.execute_reply.started":"2024-01-10T04:13:20.127651Z","shell.execute_reply":"2024-01-10T04:13:20.131506Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nimport numpy as np\nimport tensorflow as tf\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:13:24.551208Z","iopub.execute_input":"2024-01-10T04:13:24.551713Z","iopub.status.idle":"2024-01-10T04:13:24.557218Z","shell.execute_reply.started":"2024-01-10T04:13:24.551671Z","shell.execute_reply":"2024-01-10T04:13:24.556135Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n\n\nmodel = Sequential()\n\n\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(48, 48, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(7, activation='softmax'))\n\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:13:40.290695Z","iopub.execute_input":"2024-01-10T04:13:40.291512Z","iopub.status.idle":"2024-01-10T04:13:41.576071Z","shell.execute_reply.started":"2024-01-10T04:13:40.291478Z","shell.execute_reply":"2024-01-10T04:13:41.575144Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 48, 48, 32)        320       \n                                                                 \n batch_normalization (Batch  (None, 48, 48, 32)        128       \n Normalization)                                                  \n                                                                 \n conv2d_1 (Conv2D)           (None, 48, 48, 32)        9248      \n                                                                 \n batch_normalization_1 (Bat  (None, 48, 48, 32)        128       \n chNormalization)                                                \n                                                                 \n max_pooling2d (MaxPooling2  (None, 24, 24, 32)        0         \n D)                                                              \n                                                                 \n dropout (Dropout)           (None, 24, 24, 32)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 24, 24, 64)        18496     \n                                                                 \n batch_normalization_2 (Bat  (None, 24, 24, 64)        256       \n chNormalization)                                                \n                                                                 \n conv2d_3 (Conv2D)           (None, 24, 24, 64)        36928     \n                                                                 \n batch_normalization_3 (Bat  (None, 24, 24, 64)        256       \n chNormalization)                                                \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 12, 12, 64)        0         \n g2D)                                                            \n                                                                 \n dropout_1 (Dropout)         (None, 12, 12, 64)        0         \n                                                                 \n conv2d_4 (Conv2D)           (None, 12, 12, 128)       73856     \n                                                                 \n batch_normalization_4 (Bat  (None, 12, 12, 128)       512       \n chNormalization)                                                \n                                                                 \n conv2d_5 (Conv2D)           (None, 12, 12, 128)       147584    \n                                                                 \n batch_normalization_5 (Bat  (None, 12, 12, 128)       512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 6, 6, 128)         0         \n g2D)                                                            \n                                                                 \n dropout_2 (Dropout)         (None, 6, 6, 128)         0         \n                                                                 \n flatten (Flatten)           (None, 4608)              0         \n                                                                 \n dense (Dense)               (None, 512)               2359808   \n                                                                 \n batch_normalization_6 (Bat  (None, 512)               2048      \n chNormalization)                                                \n                                                                 \n dropout_3 (Dropout)         (None, 512)               0         \n                                                                 \n dense_1 (Dense)             (None, 7)                 3591      \n                                                                 \n=================================================================\nTotal params: 2653671 (10.12 MB)\nTrainable params: 2651751 (10.12 MB)\nNon-trainable params: 1920 (7.50 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_generator = ImageDataGenerator(rescale=1./255)\ntest_data_generator = ImageDataGenerator(rescale=1./255)\n\ntrain_data = train_data_generator.flow_from_directory(\n    os.path.join(dataset_path, 'train'),\n    color_mode='grayscale',\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True\n)\n\ntest_data = test_data_generator.flow_from_directory(\n    os.path.join(dataset_path, 'test'),\n    color_mode='grayscale',\n    target_size=input_shape[:2],\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:13:50.176690Z","iopub.execute_input":"2024-01-10T04:13:50.177053Z","iopub.status.idle":"2024-01-10T04:14:23.828487Z","shell.execute_reply.started":"2024-01-10T04:13:50.177026Z","shell.execute_reply":"2024-01-10T04:14:23.827691Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 28044 images belonging to 7 classes.\nFound 7177 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"num_train_samples = 28044\nnum_test_samples = 7177","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:14:31.165505Z","iopub.execute_input":"2024-01-10T04:14:31.166361Z","iopub.status.idle":"2024-01-10T04:14:31.170856Z","shell.execute_reply.started":"2024-01-10T04:14:31.166328Z","shell.execute_reply":"2024-01-10T04:14:31.169870Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import Adam, RMSprop, SGD, Adagrad,Nadam","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:14:34.443672Z","iopub.execute_input":"2024-01-10T04:14:34.444330Z","iopub.status.idle":"2024-01-10T04:14:34.448853Z","shell.execute_reply.started":"2024-01-10T04:14:34.444296Z","shell.execute_reply":"2024-01-10T04:14:34.447916Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n\n# Compile the model with Nadam optimizer and the specified learning rate\nmodel.compile(loss='categorical_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:14:36.405305Z","iopub.execute_input":"2024-01-10T04:14:36.406006Z","iopub.status.idle":"2024-01-10T04:14:36.427026Z","shell.execute_reply.started":"2024-01-10T04:14:36.405972Z","shell.execute_reply":"2024-01-10T04:14:36.426036Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:14:38.476625Z","iopub.execute_input":"2024-01-10T04:14:38.477542Z","iopub.status.idle":"2024-01-10T04:14:38.482714Z","shell.execute_reply.started":"2024-01-10T04:14:38.477509Z","shell.execute_reply":"2024-01-10T04:14:38.481594Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Define EarlyStopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=7)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:14:39.951037Z","iopub.execute_input":"2024-01-10T04:14:39.951434Z","iopub.status.idle":"2024-01-10T04:14:39.956461Z","shell.execute_reply.started":"2024-01-10T04:14:39.951403Z","shell.execute_reply":"2024-01-10T04:14:39.955329Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    steps_per_epoch=num_train_samples // batch_size,\n    epochs=10,\n    callbacks=[early_stopping],\n    batch_size=batch_size,\n    validation_data=test_data,  # Add validation data\n    validation_steps=num_test_samples // batch_size  # Specify validation steps\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:14:51.884190Z","iopub.execute_input":"2024-01-10T04:14:51.885176Z","iopub.status.idle":"2024-01-10T04:22:43.683050Z","shell.execute_reply.started":"2024-01-10T04:14:51.885139Z","shell.execute_reply":"2024-01-10T04:22:43.682020Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2024-01-10 04:14:54.509802: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"438/438 [==============================] - 210s 461ms/step - loss: 1.9328 - accuracy: 0.3380 - val_loss: 1.8110 - val_accuracy: 0.3400\nEpoch 2/10\n438/438 [==============================] - 29s 66ms/step - loss: 1.4421 - accuracy: 0.4575 - val_loss: 1.5767 - val_accuracy: 0.4198\nEpoch 3/10\n438/438 [==============================] - 29s 66ms/step - loss: 1.2814 - accuracy: 0.5130 - val_loss: 1.2537 - val_accuracy: 0.5321\nEpoch 4/10\n438/438 [==============================] - 29s 67ms/step - loss: 1.1987 - accuracy: 0.5428 - val_loss: 1.3721 - val_accuracy: 0.4819\nEpoch 5/10\n438/438 [==============================] - 29s 67ms/step - loss: 1.1460 - accuracy: 0.5659 - val_loss: 1.1625 - val_accuracy: 0.5589\nEpoch 6/10\n438/438 [==============================] - 29s 67ms/step - loss: 1.0871 - accuracy: 0.5888 - val_loss: 1.1576 - val_accuracy: 0.5647\nEpoch 7/10\n438/438 [==============================] - 29s 66ms/step - loss: 1.0520 - accuracy: 0.6053 - val_loss: 1.1465 - val_accuracy: 0.5763\nEpoch 8/10\n438/438 [==============================] - 29s 65ms/step - loss: 1.0329 - accuracy: 0.6100 - val_loss: 1.2053 - val_accuracy: 0.5738\nEpoch 9/10\n438/438 [==============================] - 30s 68ms/step - loss: 0.9831 - accuracy: 0.6338 - val_loss: 1.1765 - val_accuracy: 0.5575\nEpoch 10/10\n438/438 [==============================] - 29s 66ms/step - loss: 0.9475 - accuracy: 0.6469 - val_loss: 1.0950 - val_accuracy: 0.5989\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:22:50.291949Z","iopub.execute_input":"2024-01-10T04:22:50.293290Z","iopub.status.idle":"2024-01-10T04:22:50.298666Z","shell.execute_reply.started":"2024-01-10T04:22:50.293239Z","shell.execute_reply":"2024-01-10T04:22:50.297623Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test data\ny_true = test_data.classes  # Assuming you're using flow_from_directory\npredictions = model.predict(test_data)\n\n# Convert predictions to class labels\ny_pred = np.argmax(predictions, axis=1)\n\n# Compute metrics\naccuracy = accuracy_score(y_true, y_pred)\nprecision = precision_score(y_true, y_pred, average='weighted')\nrecall = recall_score(y_true, y_pred, average='weighted')\nf1 = f1_score(y_true, y_pred, average='weighted')\n\n# If binary classification, compute AUC  # AUC is not applicable for multi-class\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:22:54.532169Z","iopub.execute_input":"2024-01-10T04:22:54.533214Z","iopub.status.idle":"2024-01-10T04:23:00.625420Z","shell.execute_reply.started":"2024-01-10T04:22:54.533178Z","shell.execute_reply":"2024-01-10T04:23:00.624309Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"113/113 [==============================] - 6s 50ms/step\nAccuracy: 0.5985787933677024\nPrecision: 0.6086648061780819\nRecall: 0.5985787933677024\nF1 Score: 0.5854420721146442\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(\n    test_data,\n    steps=num_test_samples // batch_size\n)\n\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:23:17.880257Z","iopub.execute_input":"2024-01-10T04:23:17.880724Z","iopub.status.idle":"2024-01-10T04:23:28.225097Z","shell.execute_reply.started":"2024-01-10T04:23:17.880687Z","shell.execute_reply":"2024-01-10T04:23:28.223939Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"112/112 [==============================] - 6s 52ms/step - loss: 1.0950 - accuracy: 0.5989\nTest Loss: 1.0949565172195435\nTest Accuracy: 0.5989118218421936\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom keras.models import Model\n\n# Extract features from the last convolutional layer\nconv_output = model.get_layer('conv2d_5').output  # Adjust the layer name based on your model summary\nfeature_extraction_model = Model(inputs=model.input, outputs=conv_output)\n\n# Get features for the training data\ntrain_features = feature_extraction_model.predict(train_data)\n\n# Reshape the features to be 1D arrays for each sample\ntrain_features_1d = train_features.reshape((num_train_samples, -1))\n\n# Get features for the test data\ntest_features = feature_extraction_model.predict(test_data)\n\n# Reshape the features to be 1D arrays for each sample\ntest_features_1d = test_features.reshape((num_test_samples, -1))\n\n# Preprocess the features using StandardScaler\nscaler = StandardScaler()\n\n# Fit on training data\nscaler.fit(train_features_1d)\n\n# Transform training and test features\ntrain_features_scaled = scaler.transform(train_features_1d)\ntest_features_scaled = scaler.transform(test_features_1d)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:23:37.680814Z","iopub.execute_input":"2024-01-10T04:23:37.681755Z","iopub.status.idle":"2024-01-10T04:24:18.043613Z","shell.execute_reply.started":"2024-01-10T04:23:37.681720Z","shell.execute_reply":"2024-01-10T04:24:18.042755Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"439/439 [==============================] - 23s 52ms/step\n113/113 [==============================] - 6s 54ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.decomposition import KernelPCA, IncrementalPCA\nfrom sklearn.model_selection import train_test_split\nsubset_size = 5000\ntrain_features_scaled_subset, _, train_data_subset, _ = train_test_split(\n    train_features_scaled, train_data.classes, train_size=subset_size, random_state=42\n)\n\n# Batch processing for faster experimentation\nbatch_size = 1000\nnum_batches = len(train_features_scaled_subset) // batch_size\n\n# Apply Incremental PCA for dimensionality reduction\nn_components = 50\nipca = IncrementalPCA(n_components=n_components, batch_size=batch_size)\n\n# Process data in batches\nfor i in range(num_batches):\n    start_idx = i * batch_size\n    end_idx = (i + 1) * batch_size\n\n    train_features_kpca_batch = ipca.fit_transform(train_features_scaled_subset[start_idx:end_idx])\n\n# Transform the test data using IPCA\ntest_features_kpca_ipca = ipca.transform(test_features_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:24:33.998884Z","iopub.execute_input":"2024-01-10T04:24:33.999825Z","iopub.status.idle":"2024-01-10T04:24:58.919797Z","shell.execute_reply.started":"2024-01-10T04:24:33.999788Z","shell.execute_reply":"2024-01-10T04:24:58.918173Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, BaggingClassifier\nfrom sklearn.svm import SVC, NuSVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Define a list of classifiers\nclassifiers = [\n    ('KNN', KNeighborsClassifier()),\n    ('LDA', LinearDiscriminantAnalysis()),\n    ('RF', RandomForestClassifier()),\n    ('AdaBoost', AdaBoostClassifier()),\n    ('ETC', ExtraTreesClassifier()),\n    ('XBC', XGBClassifier()),\n    ('SVM', SVC()),\n    ('Bagging', BaggingClassifier()),\n    \n    ('GBC', GradientBoostingClassifier())\n]\n\n# Train and evaluate each classifier\nfor name, classifier in classifiers:\n    # Use the full training dataset\n    classifier.fit(train_features_kpca_batch, train_data_subset[:batch_size])\n    predictions = classifier.predict(test_features_kpca_ipca)\n    accuracy = accuracy_score(test_data.classes, predictions)\n    print(f\"{name} Accuracy on the test set: {accuracy * 100:.2f}%\")\n\n# Create a stacked ensemble model\nstacked_model = StackingClassifier(\n    estimators=classifiers,\n    final_estimator=LogisticRegression()\n)\n\n# Train the stacked ensemble model\nstacked_model.fit(train_features_kpca_batch, train_data_subset[:batch_size])\n\n# Make predictions on the test set using the stacked model\nstacked_predictions = stacked_model.predict(test_features_kpca_ipca)\n\n# Evaluate the accuracy of the stacked model\nstacked_accuracy = accuracy_score(test_data.classes, stacked_predictions)\nprint(f\"Stacked Model Accuracy on the test set: {stacked_accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-01-10T04:27:24.034505Z","iopub.execute_input":"2024-01-10T04:27:24.034945Z","iopub.status.idle":"2024-01-10T04:29:01.809580Z","shell.execute_reply.started":"2024-01-10T04:27:24.034911Z","shell.execute_reply":"2024-01-10T04:29:01.808129Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"KNN Accuracy on the test set: 17.42%\nLDA Accuracy on the test set: 17.88%\nRF Accuracy on the test set: 20.96%\nAdaBoost Accuracy on the test set: 17.40%\nETC Accuracy on the test set: 20.90%\nXBC Accuracy on the test set: 18.42%\nSVM Accuracy on the test set: 19.20%\nBagging Accuracy on the test set: 18.85%\nGBC Accuracy on the test set: 19.02%\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Stacked Model Accuracy on the test set: 21.55%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}